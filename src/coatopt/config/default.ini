[General]
root_dir = "./"
data_dir = "./data"
load_model = False
load_model_path = "root"
materials_file = "default"
continue_training = False

[Data]
n_layers = 8
min_thickness = 1e-10
max_thickness = 300e-9
use_observation = True
use_intermediate_reward = False
ignore_air_option = False
ignore_substrate_option = False
optimise_parameters = ["reflectivity", "thermal_noise", "absorption"]
optimise_targets = {"reflectivity":1.0, "thermal_noise":1e-21, "absorption":0.01}
design_criteria = {"reflectivity":0.99999, "thermal_noise":5.394480540642821e-21, "absorption":0.01}
optimise_weight_ranges = {"reflectivity":(0.0, 1.0), "thermal_noise":(0.0, 1.0), "absorption":(0.0, 1.0)}

# Objective bounds for reward normalization and optimization constraints
# Leave empty to use automatic bounds from reward functions
objective_bounds = {}  # Example: {"reflectivity": [1e-6, 1e-1], "absorption": [1e-4, 1000.0]}

use_optical_thickness = True
combine = "logproduct"
reward_function = "default"

# Electric field configuration
include_electric_field = False
electric_field_points = 50

# Reward normalization parameters
use_reward_normalization = False
reward_normalization_mode = "fixed"
reward_normalization_ranges = {}  # Leave empty to auto-compute from objective bounds
reward_normalization_alpha = 0.1

[Network]
model_type = "hppo"  # Options: "hppo", "multiobjective", "genetic"
hyper_networks = False
include_layer_number = True
include_material_in_policy = False
pre_network_type = "lstm"
hidden_size = 32
n_pre_layers = 2

n_value_layers = 2
n_continuous_layers = 2
n_discrete_layers = 2
continuous_hidden_size = 16
discrete_hidden_size = 16
value_hidden_size = 16
buffer_size = 10000

# Mixture of Experts parameters
use_mixture_of_experts = False
moe_n_experts = 5
moe_expert_specialization = "sobol_sequence"  # Options: "sobol_sequence", "random", "adaptive_constraints"
moe_gate_hidden_dim = 64
moe_gate_temperature = 1.0
moe_load_balancing_weight = 0.01

# Adaptive constraints configuration (for moe_expert_specialization = "adaptive_constraints")
moe_constraint_experts_per_objective = 2
moe_constraint_penalty_weight = 100.0
moe_phase1_episodes = 1000

[Training]
n_iterations = 8000
lr_discrete_policy = 0.0001
lr_continuous_policy = 0.0001
lr_value = 0.001
n_episodes_per_update = 256
n_epochs_per_update = 5
clip_ratio = 0.01
gamma = 0.999
batch_size = 256
optimiser = "adam"
device = "cuda:0"
model_save_interval = 10

# Entropy regularization parameters (separate for discrete and continuous policies)
entropy_beta_start = 1.0
entropy_beta_end = 0.001
entropy_beta_decay_length = None
entropy_beta_decay_start = 0
entropy_beta_use_restarts = False

# Alternative: separate discrete/continuous entropy betas (recommended for multiobjective)
entropy_beta_discrete_start = 0.1
entropy_beta_discrete_end = 0.01
entropy_beta_continuous_start = 0.05
entropy_beta_continuous_end = 0.001

# Learning rate scheduling
scheduler_start = 0
scheduler_end = -1
lr_step = 5000
lr_min = 1e-5
t_mult = 2

n_init_solutions = 1000

final_weight_epoch = 1
start_weight_alpha = 1.0
final_weight_alpha = 1.0
cycle_weights="smooth"
n_weight_cycles=1
weight_network_save = False

[MCMC]
n_walkers = 32
n_steps = 1000

[Genetic]
algorithm="ngsa2"
population_size = 100
crossover_probability = 0.1
thickness_sigma = 1e-9
n_generations = 1000
crossover_eta = 20
mutation_probability = 0.1
mutation_eta = 20
eliminate_duplicates = True
n_neighbors = None  # For MOEAD
prob_neighbor_mating = None  # For MOEAD
n_partitions = None  # For NSGA3/MOEAD reference directions
seed = 1234

