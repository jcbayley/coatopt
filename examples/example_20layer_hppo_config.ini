[General]
# update this root dir to the output directory you want
root_dir = "root_path"
load_model = False
load_model_path = "root"
# link to the materials json file here
materials_file = "pathto/example_20_layer_hppo_materials.json"
# set to true if you want to continue from a pre trained model
continue_training = False

[Data]
# number of layers in stack
n_layers = 20
# min and max thickness of the layers in optical thickness
use_optical_thickness=True
min_thickness = 0.01
max_thickness = 0.4
# whether to use the observation space (n,thickness etc) or the state (material label, thickness)
use_observation = False
# allow to choose air and end stack early
ignore_air_option = True
ignore_substrate_option = False
# choice of reward function (should be set to true at the moment)
use_ligo_reward = True
# which parameters to optimise over and their targets
optimise_parameters = ["reflectivity", "thermal_noise", "absorption"]
optimise_targets = {"reflectivity":0.99999, "thermal_noise":5.394480540642821e-21, "absorption":1}
# use a reward at each step
use_intermediate_reward = False
include_random_rare_state = False
# how to combins the individual rewards from parameters
combine="logproduct"

[Network]
# network parameters for 4 neural networks used within hppo
model_type = "hppo"
include_layer_number = True
include_material_in_policy = True
pre_network_type = "lstm"
hidden_size = 32
pre_n_layers = 3

n_value_layers = 4
n_continuous_layers = 3
n_discrete_layers = 3
continuous_hidden_size = 16
discrete_hidden_size = 16
value_hidden_size = 16

[Training]
# lots of hyperparameters for the training
# most are not too important so can be left as these values
n_iterations = 15000
lr_discrete_policy = 0.001
lr_continuous_policy = 0.001
lr_value = 0.002
lr_step = 1500
lr_min=1e-4
T_mult = 0.5
n_episodes_per_update = 64
n_epochs_per_update = 10
clip_ratio = 0.01
gamma = 0.999
batch_size = 256
optimiser = "adam"
device = "cuda:0"
model_save_interval = 2

entropy_beta_start=0.01
entropy_beta_end=0.01
entropy_beta_decay_length=1500
entropy_beta_decay_start=0

scheduler_start = 0
scheduler_end = 1501
